{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import tifffile\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from skimage import color, data\n",
    "from skimage.color import rgb2gray\n",
    "from itertools import product\n",
    "import os\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths:\n",
    "dir_tif = \"data/doq_data/\"\n",
    "dir_rgb = \"./data/doq_data_256/\"\n",
    "dir_gray = \"./data/doq_data_256_gray/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tif files:\n",
    "file1 = \"C3311604.SES.100201791.tif\"\n",
    "file2 = \"C4712134.NES.100228298.tif\"\n",
    "file3 = \"O3712206.SWS.53377.tif\"\n",
    "file4 = \"O3712208.SWS.53164.tif\"\n",
    "file5 = \"O3712223.SES.53274.tif\"\n",
    "file6 = \"O3712232.NWS.53174.tif\"\n",
    "file7 = \"O3910434.NES.1137827.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Tif images to tiles:\n",
    "def split_images_to_tiles(filename, dir_in, dir_out, d):\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    img = Image.open(os.path.join(dir_in, filename))\n",
    "    w, h = img.size\n",
    "    \n",
    "    grid = product(range(0, h-h%d, d), range(0, w-w%d, d))\n",
    "    for i, j in grid:\n",
    "        box = (j, i, j+d, i+d)\n",
    "        out = os.path.join(dir_out, f'{name}_{i}_{j}{ext}')\n",
    "        img.crop(box).save(out)\n",
    "\n",
    "    return None\n",
    "\n",
    "## creates an array of filenames in dir_in \n",
    "def create_filename_array(dir_in):\n",
    "    directory_files = os.listdir(dir_in)\n",
    "    filename_array = []\n",
    "    for file in directory_files:\n",
    "        d = str(dir_in + \"/\" + file)\n",
    "        filename_array.append(d)\n",
    "    return filename_array\n",
    "\n",
    "## Read RGB files from dir_in directory filenames, converts them to gray-scale, and saves as png images.\n",
    "def convert_tiles_to_grayscale(filename_array, dir_in, dir_out):\n",
    "    for file in filename_array:\n",
    "        dir_in, fileextension =  os.path.splitext(file)    ## split directory + filename + extension\n",
    "        filename = os.path.basename(dir_in)                ## read filename only \n",
    "        tile_rgb = tifffile.imread(file)                     ## read image as tifffile\n",
    "        tile_gray = rgb2gray(tile_rgb)\n",
    "        #tile_gray = color.rgb2gray(tile_rgb, channel_axis=-1)\n",
    "        img = Image.fromarray(tile_gray*255).convert('L').save(dir_out + filename + \".png\")\n",
    "        \n",
    "    return None\n",
    "\n",
    "\n",
    "# Converts grayscale tif image tiles to png\n",
    "def convert_tif_tiles_to_png(filename_array, dir_out):\n",
    "    for file in filename_array:\n",
    "        dir_in, fileextension =  os.path.splitext(file)    ## split directory + filename + extension\n",
    "        filename = os.path.basename(dir_in)                ## read filename only \n",
    "        tile_tif = tifffile.imread(file)                   ## read image as tifffile                  \n",
    "        img = Image.fromarray(tile_tif).convert('L').save(dir_out + filename + \".png\")\n",
    "    return None\n",
    "\n",
    "## creates an array of filenames in dir_in \n",
    "def create_gray_image_tile_array(dir_out): \n",
    "    gray_directory_files = os.listdir(dir_out)\n",
    "    gray_file_names = []\n",
    "    for file in gray_directory_files:\n",
    "        d = str(dir_out + file)\n",
    "        gray_file_names.append(d)\n",
    "\n",
    "    ## Read gray files from dir_in directory filenames and save them as an numpy array.\n",
    "    directory_array = []\n",
    "\n",
    "    for file in gray_file_names:\n",
    "        img = plt.imread(file)  ## numpy.ndarray\n",
    "        directory_array.append(img)\n",
    "\n",
    "    # torch expects type    \n",
    "    # datasets.arrow_dataset.Dataset  \n",
    "    return directory_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. splitting rgb images to RGB tiles:\n",
    "# split_images_to_tiles(filename= file2, dir_in= \"data/doq_data/\", dir_out=\"data/doq_data_256/\", d=256)\n",
    "# split_images_to_tiles(filename= file7, dir_in= \"data/doq_data/gray/\", dir_out = \"data/doq_data/gray_256_tif/\", d=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. creating filename array:\n",
    "# filename_array_rgb = create_filename_array(dir_in = \"data/doq_data_256\")\n",
    "# print(len(filename_array_rgb)) # 4785 from 7 tiffiles\n",
    "\n",
    "# filename_array_gray = create_filename_array(\"data/doq_data/gray_256_tif\")\n",
    "# print(filename_array_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. converting all images to Grayscale and saving them to a separate folder:\n",
    "# convert_tiles_to_grayscale(filename_array, dir_in=dir_rgb, dir_out=\"./data/doq_data_gray_256/\")\n",
    "\n",
    "# 3. save gray tif files to png:\n",
    "# convert_tif_tiles_to_png(filename_array_gray, dir_out=\"./data/doq_data_gray_256/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_array = create_gray_image_tile_array(dir_out=\"./data/doq_data_gray_256/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"gray_image_tile_array_256\", file_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr= np.load(\"./data/gray_image_tile_array_64.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79052, 1.0, 0.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr), np.max(arr), np.min(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the dataset to Huggingface Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766b1527abee461d8e7392461cb1e67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# https://huggingface.co/docs/datasets/upload_dataset\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b704e9310b83418cbee83c5a82806c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/79052 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4201f52a51bb4bdda8c138ff81f9e554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"data/doq_data_gray_64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06be95f16e72462d8038a7fe5ad6501b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbe34aee26f412a98161cf538061bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/79052 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fea4119efb548fc82e5609b71ad94e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/791 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ReginaFoley/doq_data_64/commit/8e5a2e5b8a172cb4ecd70ceecc79e14469a0e960', commit_message='Upload dataset', commit_description='', oid='8e5a2e5b8a172cb4ecd70ceecc79e14469a0e960', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"ReginaFoley/doq_data_64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
